\section{Methodology}

\subsection*{Data Collection}
\label{Methodology:DC}

\subsection*{Data processing}

\subsection*{Support Vector Machine (SVM)}
\label{Methodology:SVM_model}
SVM classifiers are generated in two steps; training data is ``projected'' into a high dimensional space, which is usually higher than the input data. From there the algorithm finds a hyperplane in this new feature space with the largest margin of classification differences. It is shown that classification accuracy depends only weakly on the specific projection, provided that the target space is sufficiently high dimensional \cite{cortes1995support}. In extream cases, it may not possible to find the separating hyperplane even in a very high-dimensional space. This is when a tradeoff is introduced between the size of the separating margin and penalties for every vector which is
within the margin.


\subsection*{Model}
\label{Methodology:1DCNN_model}

The neural network we used is a <something>

\subsection*{Model training}

Our data was broken up into different genomic datasets as descibes in \ref{Methodology:DC}