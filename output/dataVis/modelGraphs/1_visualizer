digraph {
	graph [size="16.95,16.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140165610434928 [label="
 (500, 1)" fillcolor=darkolivegreen1]
	140165610364560 [label=SigmoidBackward0]
	140165610364496 -> 140165610364560
	140165610364496 [label=AddmmBackward0]
	140165610364752 -> 140165610364496
	140165610347984 [label="layer_out.bias
 (1)" fillcolor=lightblue]
	140165610347984 -> 140165610364752
	140165610364752 [label=AccumulateGrad]
	140165610364816 -> 140165610364496
	140165610364816 [label=ReluBackward0]
	140165610364624 -> 140165610364816
	140165610364624 [label=AddmmBackward0]
	140165610451408 -> 140165610364624
	140165610347792 [label="layer_7.bias
 (3)" fillcolor=lightblue]
	140165610347792 -> 140165610451408
	140165610451408 [label=AccumulateGrad]
	140165610451536 -> 140165610364624
	140165610451536 [label=ReluBackward0]
	140165610451344 -> 140165610451536
	140165610451344 [label=AddmmBackward0]
	140165610451664 -> 140165610451344
	140165610347600 [label="layer_6.bias
 (7)" fillcolor=lightblue]
	140165610347600 -> 140165610451664
	140165610451664 [label=AccumulateGrad]
	140165610451920 -> 140165610451344
	140165610451920 [label=ReluBackward0]
	140165610451728 -> 140165610451920
	140165610451728 [label=AddmmBackward0]
	140165610452048 -> 140165610451728
	140165610347408 [label="layer_5.bias
 (15)" fillcolor=lightblue]
	140165610347408 -> 140165610452048
	140165610452048 [label=AccumulateGrad]
	140165610452304 -> 140165610451728
	140165610452304 [label=ReluBackward0]
	140165610452112 -> 140165610452304
	140165610452112 [label=AddmmBackward0]
	140165610452432 -> 140165610452112
	140165610347216 [label="layer_4.bias
 (31)" fillcolor=lightblue]
	140165610347216 -> 140165610452432
	140165610452432 [label=AccumulateGrad]
	140165610452688 -> 140165610452112
	140165610452688 [label=ReluBackward0]
	140165610452496 -> 140165610452688
	140165610452496 [label=AddmmBackward0]
	140165610452816 -> 140165610452496
	140165610345584 [label="layer_3.bias
 (62)" fillcolor=lightblue]
	140165610345584 -> 140165610452816
	140165610452816 [label=AccumulateGrad]
	140165610453072 -> 140165610452496
	140165610453072 [label=ReluBackward0]
	140165610452880 -> 140165610453072
	140165610452880 [label=AddmmBackward0]
	140165610453200 -> 140165610452880
	140165624396784 [label="layer_2.bias
 (125)" fillcolor=lightblue]
	140165624396784 -> 140165610453200
	140165610453200 [label=AccumulateGrad]
	140165610453456 -> 140165610452880
	140165610453456 [label=ReluBackward0]
	140165610453264 -> 140165610453456
	140165610453264 [label=AddmmBackward0]
	140165610453584 -> 140165610453264
	140168521236112 [label="layer_1.bias
 (250)" fillcolor=lightblue]
	140168521236112 -> 140165610453584
	140165610453584 [label=AccumulateGrad]
	140165610453840 -> 140165610453264
	140165610453840 [label=TBackward0]
	140165610453712 -> 140165610453840
	140168504500400 [label="layer_1.weight
 (250, 500)" fillcolor=lightblue]
	140168504500400 -> 140165610453712
	140165610453712 [label=AccumulateGrad]
	140165610453392 -> 140165610452880
	140165610453392 [label=TBackward0]
	140165610453136 -> 140165610453392
	140165624434960 [label="layer_2.weight
 (125, 250)" fillcolor=lightblue]
	140165624434960 -> 140165610453136
	140165610453136 [label=AccumulateGrad]
	140165610453008 -> 140165610452496
	140165610453008 [label=TBackward0]
	140165610452752 -> 140165610453008
	140165624435056 [label="layer_3.weight
 (62, 125)" fillcolor=lightblue]
	140165624435056 -> 140165610452752
	140165610452752 [label=AccumulateGrad]
	140165610452624 -> 140165610452112
	140165610452624 [label=TBackward0]
	140165610452368 -> 140165610452624
	140165610346928 [label="layer_4.weight
 (31, 62)" fillcolor=lightblue]
	140165610346928 -> 140165610452368
	140165610452368 [label=AccumulateGrad]
	140165610452240 -> 140165610451728
	140165610452240 [label=TBackward0]
	140165610451984 -> 140165610452240
	140165610347312 [label="layer_5.weight
 (15, 31)" fillcolor=lightblue]
	140165610347312 -> 140165610451984
	140165610451984 [label=AccumulateGrad]
	140165610451856 -> 140165610451344
	140165610451856 [label=TBackward0]
	140165610451600 -> 140165610451856
	140165610347504 [label="layer_6.weight
 (7, 15)" fillcolor=lightblue]
	140165610347504 -> 140165610451600
	140165610451600 [label=AccumulateGrad]
	140165610451024 -> 140165610364624
	140165610451024 [label=TBackward0]
	140165610451216 -> 140165610451024
	140165610347696 [label="layer_7.weight
 (3, 7)" fillcolor=lightblue]
	140165610347696 -> 140165610451216
	140165610451216 [label=AccumulateGrad]
	140165610451280 -> 140165610364496
	140165610451280 [label=TBackward0]
	140165610451152 -> 140165610451280
	140165610347888 [label="layer_out.weight
 (1, 3)" fillcolor=lightblue]
	140165610347888 -> 140165610451152
	140165610451152 [label=AccumulateGrad]
	140165610364560 -> 140165610434928
}
