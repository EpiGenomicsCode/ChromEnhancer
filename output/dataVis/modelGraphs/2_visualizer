digraph {
	graph [size="24.75,24.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140583921862800 [label="
 (500, 1)" fillcolor=darkolivegreen1]
	140583935695440 [label=SigmoidBackward0]
	140583935694032 -> 140583935695440
	140583935694032 [label=AddmmBackward0]
	140587261550096 -> 140583935694032
	140583921861360 [label="DNN.layer_out.bias
 (1)" fillcolor=lightblue]
	140583921861360 -> 140587261550096
	140587261550096 [label=AccumulateGrad]
	140583921749200 -> 140583935694032
	140583921749200 [label=ReluBackward0]
	140583935694288 -> 140583921749200
	140583935694288 [label=AddmmBackward0]
	140583921747344 -> 140583935694288
	140583921861168 [label="DNN.layer_7.bias
 (3)" fillcolor=lightblue]
	140583921861168 -> 140583921747344
	140583921747344 [label=AccumulateGrad]
	140583921747152 -> 140583935694288
	140583921747152 [label=ReluBackward0]
	140583921747472 -> 140583921747152
	140583921747472 [label=AddmmBackward0]
	140583921747024 -> 140583921747472
	140583921860976 [label="DNN.layer_6.bias
 (7)" fillcolor=lightblue]
	140583921860976 -> 140583921747024
	140583921747024 [label=AccumulateGrad]
	140583921746704 -> 140583921747472
	140583921746704 [label=ReluBackward0]
	140583921746960 -> 140583921746704
	140583921746960 [label=AddmmBackward0]
	140583921746768 -> 140583921746960
	140583921860784 [label="DNN.layer_5.bias
 (15)" fillcolor=lightblue]
	140583921860784 -> 140583921746768
	140583921746768 [label=AccumulateGrad]
	140583921746512 -> 140583921746960
	140583921746512 [label=ReluBackward0]
	140583921748688 -> 140583921746512
	140583921748688 [label=AddmmBackward0]
	140583921746448 -> 140583921748688
	140583921827664 [label="DNN.layer_4.bias
 (31)" fillcolor=lightblue]
	140583921827664 -> 140583921746448
	140583921746448 [label=AccumulateGrad]
	140583921746256 -> 140583921748688
	140583921746256 [label=ReluBackward0]
	140583921746384 -> 140583921746256
	140583921746384 [label=AddmmBackward0]
	140583921748240 -> 140583921746384
	140583921827472 [label="DNN.layer_3.bias
 (62)" fillcolor=lightblue]
	140583921827472 -> 140583921748240
	140583921748240 [label=AccumulateGrad]
	140583921748112 -> 140583921746384
	140583921748112 [label=ReluBackward0]
	140583921746192 -> 140583921748112
	140583921746192 [label=AddmmBackward0]
	140583921747984 -> 140583921746192
	140583921827280 [label="DNN.layer_2.bias
 (125)" fillcolor=lightblue]
	140583921827280 -> 140583921747984
	140583921747984 [label=AccumulateGrad]
	140583921749136 -> 140583921746192
	140583921749136 [label=ReluBackward0]
	140583921749072 -> 140583921749136
	140583921749072 [label=AddmmBackward0]
	140583921749584 -> 140583921749072
	140583921827088 [label="DNN.layer_1.bias
 (250)" fillcolor=lightblue]
	140583921827088 -> 140583921749584
	140583921749584 [label=AccumulateGrad]
	140583921748752 -> 140583921749072
	140583921748752 [label=ReluBackward0]
	140583921749840 -> 140583921748752
	140583921749840 [label=AddmmBackward0]
	140583921748880 -> 140583921749840
	140583921826224 [label="layer_4.bias
 (500)" fillcolor=lightblue]
	140583921826224 -> 140583921748880
	140583921748880 [label=AccumulateGrad]
	140583921749456 -> 140583921749840
	140583921749456 [label=ReshapeAliasBackward0]
	140583921746576 -> 140583921749456
	140583921746576 [label=ReluBackward0]
	140583921749776 -> 140583921746576
	140583921749776 [label=ConvolutionBackward0]
	140583921688784 -> 140583921749776
	140583921688784 [label=ReluBackward0]
	140583921688912 -> 140583921688784
	140583921688912 [label=ConvolutionBackward0]
	140583921689104 -> 140583921688912
	140583921689104 [label=ReluBackward0]
	140583921689296 -> 140583921689104
	140583921689296 [label=ConvolutionBackward0]
	140583921689488 -> 140583921689296
	140583921826416 [label="layer_1.weight
 (3, 1, 10)" fillcolor=lightblue]
	140583921826416 -> 140583921689488
	140583921689488 [label=AccumulateGrad]
	140583921689616 -> 140583921689296
	140583921826320 [label="layer_1.bias
 (3)" fillcolor=lightblue]
	140583921826320 -> 140583921689616
	140583921689616 [label=AccumulateGrad]
	140583921689232 -> 140583921688912
	140583921826512 [label="layer_2.weight
 (5, 3, 50)" fillcolor=lightblue]
	140583921826512 -> 140583921689232
	140583921689232 [label=AccumulateGrad]
	140583921688976 -> 140583921688912
	140583921826608 [label="layer_2.bias
 (5)" fillcolor=lightblue]
	140583921826608 -> 140583921688976
	140583921688976 [label=AccumulateGrad]
	140583921688848 -> 140583921749776
	140583921826704 [label="layer_3.weight
 (10, 5, 100)" fillcolor=lightblue]
	140583921826704 -> 140583921688848
	140583921688848 [label=AccumulateGrad]
	140583921688656 -> 140583921749776
	140583921826800 [label="layer_3.bias
 (10)" fillcolor=lightblue]
	140583921826800 -> 140583921688656
	140583921688656 [label=AccumulateGrad]
	140583921749392 -> 140583921749840
	140583921749392 [label=TBackward0]
	140583921749648 -> 140583921749392
	140583921826992 [label="layer_4.weight
 (500, 3430)" fillcolor=lightblue]
	140583921826992 -> 140583921749648
	140583921749648 [label=AccumulateGrad]
	140583921749968 -> 140583921749072
	140583921749968 [label=TBackward0]
	140583921748432 -> 140583921749968
	140583921826896 [label="DNN.layer_1.weight
 (250, 500)" fillcolor=lightblue]
	140583921826896 -> 140583921748432
	140583921748432 [label=AccumulateGrad]
	140583921749264 -> 140583921746192
	140583921749264 [label=TBackward0]
	140583921746000 -> 140583921749264
	140583921827184 [label="DNN.layer_2.weight
 (125, 250)" fillcolor=lightblue]
	140583921827184 -> 140583921746000
	140583921746000 [label=AccumulateGrad]
	140583921748176 -> 140583921746384
	140583921748176 [label=TBackward0]
	140583921748304 -> 140583921748176
	140583921827376 [label="DNN.layer_3.weight
 (62, 125)" fillcolor=lightblue]
	140583921827376 -> 140583921748304
	140583921748304 [label=AccumulateGrad]
	140583921748368 -> 140583921748688
	140583921748368 [label=TBackward0]
	140583921748496 -> 140583921748368
	140583921827568 [label="DNN.layer_4.weight
 (31, 62)" fillcolor=lightblue]
	140583921827568 -> 140583921748496
	140583921748496 [label=AccumulateGrad]
	140583921748560 -> 140583921746960
	140583921748560 [label=TBackward0]
	140583921748816 -> 140583921748560
	140583921860688 [label="DNN.layer_5.weight
 (15, 31)" fillcolor=lightblue]
	140583921860688 -> 140583921748816
	140583921748816 [label=AccumulateGrad]
	140583921746832 -> 140583921747472
	140583921746832 [label=TBackward0]
	140583921747088 -> 140583921746832
	140583921860880 [label="DNN.layer_6.weight
 (7, 15)" fillcolor=lightblue]
	140583921860880 -> 140583921747088
	140583921747088 [label=AccumulateGrad]
	140583921746896 -> 140583935694288
	140583921746896 [label=TBackward0]
	140583921747536 -> 140583921746896
	140583921861072 [label="DNN.layer_7.weight
 (3, 7)" fillcolor=lightblue]
	140583921861072 -> 140583921747536
	140583921747536 [label=AccumulateGrad]
	140583921748624 -> 140583935694032
	140583921748624 [label=TBackward0]
	140583921747408 -> 140583921748624
	140583921861264 [label="DNN.layer_out.weight
 (1, 3)" fillcolor=lightblue]
	140583921861264 -> 140583921747408
	140583921747408 [label=AccumulateGrad]
	140583935695440 -> 140583921862800
}
